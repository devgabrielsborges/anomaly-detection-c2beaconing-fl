# Configuration for federated learning experiments

experiment:
  name: "federated-anomaly-detection"
  description: "Federated learning for C2 beaconing detection"
  tracking_uri: null # Use local file store if null

data:
  dataset: "ctu13" # Options: ctu13, ugr16
  data_path: "data/processed"
  features_to_drop:
    - "StartTime"
    - "SrcAddr"
    - "DstAddr"
    - "Label"
    - "scenario"

federated:
  num_clients: 5
  num_rounds: 10
  fraction_fit: 1.0 # Fraction of clients to sample for training
  fraction_evaluate: 1.0 # Fraction of clients to sample for evaluation
  min_fit_clients: 2
  min_evaluate_clients: 2
  min_available_clients: 2

  # Partitioning strategy
  partition_strategy: "non-iid-dirichlet" # Options: iid, non-iid-dirichlet
  dirichlet_alpha: 0.5 # Lower = more non-IID (used if partition_strategy is non-iid-dirichlet)
  client_val_size: 0.1 # Fraction of each client's data for validation

  # Strategy
  strategy: "fedavg" # Options: fedavg, fedprox
  proximal_mu: 0.1 # Only used for fedprox

  # Simulation settings
  server_address: "[::]:8080"
  use_simulation: true # If true, use Flower simulation (all in one process)

model:
  type: "neural_network" # Options: neural_network (RF and XGB don't support FL well)

  # Neural Network parameters
  neural_network:
    hidden_dims: [128, 64, 32]
    dropout_rate: 0.3
    learning_rate: 0.001
    batch_size: 256
    epochs_per_round: 1 # Local epochs per FL round
    class_weight: null # Auto-calculated if null
    random_state: 42

training:
  random_state: 42
  verbose: true

logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

output:
  model_dir: "models"
  results_dir: "results"
  plots_dir: "plots"
